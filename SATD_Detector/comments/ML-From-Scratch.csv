file path,line #,comment,satd
ML-From-Scratch/setup.py,9,get the dependencies and installs,
ML-From-Scratch/mlfromscratch/utils/misc.py,24,Sort eigenvalues and eigenvector by largest eigenvalues,
ML-From-Scratch/mlfromscratch/utils/misc.py,28,Project the data onto principal components,
ML-From-Scratch/mlfromscratch/utils/misc.py,66,Plot the dataset X and the corresponding labels y in 2D using PCA.,
ML-From-Scratch/mlfromscratch/utils/misc.py,77,Plot the different class distributions,
ML-From-Scratch/mlfromscratch/utils/misc.py,84,Plot legend,
ML-From-Scratch/mlfromscratch/utils/misc.py,88,Plot title,
ML-From-Scratch/mlfromscratch/utils/misc.py,97,Axis labels,
ML-From-Scratch/mlfromscratch/utils/misc.py,103,Plot the dataset X and the corresponding labels y in 3D using PCA.,
ML-From-Scratch/mlfromscratch/utils/data_operation.py,43,Squared distance between each coordinate,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,64,Concatenate x and y and do a random shuffle,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,69,Uses 50% of training samples without replacements,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,72,100% with replacements,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,100,X_std = (X - X.mean(axis=0)) / X.std(axis=0),
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,108,Split the training data from test data in the ratio specified in,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,109,test_size,
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,140,Add left over samples to last set as training samples,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,33,Parameters used to update velocity,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,47,Set intial best as the current initialization,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,50,Set initial velocity to zero,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,69,Two random parameters used to update the velocity,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,74,Layer weights velocity,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,81,Bias weight velocity,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,88,Update layer weights with velocity,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,104,The best individual of the population is initialized as population's first ind.,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,109,Calculate new velocity and update the NN weights,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,111,Calculate the fitness of the updated individual,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,114,If the current fitness is higher than the individual's previous highest,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,115,=> update the individual's best layer setup,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,119,If the individual's fitness is higher than the highest recorded fitness for the,
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,120,whole population => update the best individual,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,14,Project data onto vector,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,19,Separate data by class,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,23,Calculate the covariance matrices of the two datasets,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,28,Calculate the mean of the two datasets,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,33,Determine the vector which when X is projected onto it best separates the,
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,34,data by class. w = (mean1 - mean2) / (cov1 + cov2),
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,64,Insert constant ones for bias weights,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,69,Do gradient descent for n_iterations,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,72,Calculate l2 loss,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,75,Gradient of l2 loss w.r.t w,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,77,Update the weights,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,81,Insert constant ones for bias weights,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,100,No regularization,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,106,If not gradient descent => Least squares approximation of w,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,108,Insert constant ones for bias weights,
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,110,Calculate weights by least squares (using Moore-Penrose pseudoinverse),
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,163,No regularization,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,26,Within class scatter matrix:,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,27,SW = sum{ (X_for_class - mean_of_X_for_class)^2 },
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,28,<=> (n_samples_X_for_class - 1) * covar(X_for_class),
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,34,Between class scatter:,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,35,SB = sum{ n_samples_for_class * (mean_for_class - total_mean)^2 },
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,48,Determine SW^-1 * SB by calculating inverse of SW,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,51,Get eigenvalues and eigenvectors of SW^-1 * SB,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,54,Sort the eigenvalues and corresponding eigenvectors from largest,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,55,to smallest eigenvalue and select the first n_components,
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,60,Project the data onto eigenvectors,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,13,Calculate the mean and variance of each feature for each class,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,15,Only select the rows where the label equals the given class,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,18,Add the mean and variance for each feature (column),
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,25,Added in denominator to prevent division by zero,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,52,Go through list of classes,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,54,Initialize posterior as prior,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,56,Naive assumption (independence):,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,57,"P(x1,x2,x3|Y) = P(x1|Y)*P(x2|Y)*P(x3|Y)",
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,58,Posterior is product of prior and likelihoods (ignoring scaling factor),
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,60,Likelihood of feature value given distribution of feature values given y,
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,64,Return the class with the largest posterior probability,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,27,"Initialize parameters between [-1/sqrt(N), 1/sqrt(N)]",
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,33,Tune parameters for n iterations,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,35,Make a new prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,38,Move against the gradient of the loss function with,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,39,respect to the parameters to minimize the loss,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,42,Make a diagonal matrix of the sigmoid gradient column vector,
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,44,Batch opt:,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,6,Import helper functions,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,35,Number of trees,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,36,Maxmimum number of features per tree,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,38,Minimum information gain req. to continue,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,39,Maximum depth for tree,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,42,Initialize decision trees,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,53,If max_features have not been defined => select it as,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,54,sqrt(n_features),
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,58,Choose one random subset of the data for each tree,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,63,Feature bagging (select random subsets of the features),
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,65,Save the indices of the features for prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,67,Choose the features corresponding to the indices,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,69,Fit the tree to the data,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,74,Let each tree make a prediction on the data,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,76,Indices of the features that the tree has trained on,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,78,Make a prediction based on those features,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,83,For each sample,
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,85,Select the most common class prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,8,Import helper functions,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,11,Decision stump used as weak classifier in this impl. of Adaboost,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,14,Determines if sample shall be classified as -1 or 1 given threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,16,The index of the feature used to make classification,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,18,The threshold value that the feature should be measured against,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,20,Value indicative of the classifier's accuracy,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,39,Initialize weights to 1/N,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,43,Iterate through classifiers,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,46,Minimum error given for using a certain feature value threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,47,for predicting sample label,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,49,Iterate throught every unique feature value and see what value,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,50,makes the best threshold for predicting y,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,54,Try every unique feature value as threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,57,Set all predictions to '1' initially,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,59,Label the samples whose values are below threshold as '-1',
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,61,Error = sum of weights of misclassified samples,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,64,If the error is over 50% we flip the polarity so that samples that,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,65,"were classified as 0 are classified as 1, and vice versa",
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,66,E.g error = 0.8 => (1 - error) = 0.2,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,71,If this threshold resulted in the smallest error we save the,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,72,configuration,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,78,"Calculate the alpha which is used to update the sample weights,",
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,79,Alpha is also an approximation of this classifier's proficiency,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,81,Set all predictions to '1' initially,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,83,The indexes where the sample values are below threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,85,Label those as '-1',
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,87,Calculate new weights,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,88,Missclassified samples gets larger weights and correctly classified samples smaller,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,90,Normalize to one,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,93,Save classifier,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,99,For each classifier => label the samples,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,101,Set all predictions to '1' initially,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,103,The indexes where the sample values are below threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,105,Label those as '-1',
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,107,Add predictions weighted by the classifiers alpha,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,108,(alpha indicative of classifier's proficiency),
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,111,Return sign of prediction sum,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,126,"Change labels to {-1, 1}",
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,133,Adaboost classification with 5 weak classifiers,
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,141,Reduce dimensions to 2d using pca and plot the results,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,26,Index for the feature that is tested,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,27,Threshold value for feature,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,28,Value if the node is a leaf in the tree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,29,'Left' subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,30,'Right' subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,33,Super class of RegressionTree and ClassificationTree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,50,Root node in dec. tree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,51,Minimum n of samples to justify split,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,53,The minimum impurity to justify split,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,55,The maximum depth to grow the tree to,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,57,"Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)",
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,59,Function to determine prediction of y at leaf,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,61,If y is one-hot encoded (multi-dim) or not (one-dim),
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,63,If Gradient Boost,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,77,Feature index and threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,78,Subsets of the data,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,80,Check if expansion of y is needed,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,84,Add y as last column of X,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,90,Calculate the impurity for each feature,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,92,All values of feature_i,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,96,Iterate through all unique values of feature column i and,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,97,calculate the impurity,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,99,Divide X and y depending on if the feature value of X at index feature_i,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,100,meets the threshold,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,104,Select the y-values of the two sets,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,108,Calculate impurity,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,111,If this threshold resulted in a higher information gain than previously,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,112,recorded save the threshold value and the feature,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,113,index,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,118,X of left subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,119,y of left subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,120,X of right subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,121,y of right subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,125,Build subtrees for the right and left branches,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,131,We're at leaf => determine value,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,144,If we have a value (i.e we're at a leaf) => return value as the prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,148,Choose the feature that we will test,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,151,Determine if we will follow left or right branch,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,159,Test subtree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,172,If we're at leaf => print the label,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,175,Go deeper down the tree,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,177,Print test,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,179,Print the true scenario,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,182,Print the false scenario,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,208,Split,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,219,"y split into y, y_pred",
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,221,Newton's Method,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,242,Calculate the variance reduction,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,258,Calculate information gain,
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,271,Count number of occurences of samples with label,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,34,Hidden layer,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,38,Output layer,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,49,..............,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,50,Forward Pass,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,51,..............,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,53,HIDDEN LAYER,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,56,OUTPUT LAYER,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,60,...............,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,61,Backward Pass,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,62,...............,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,64,OUTPUT LAYER,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,65,Grad. w.r.t input of output layer,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,69,HIDDEN LAYER,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,70,Grad. w.r.t input of hidden layer,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,75,Update weights (by gradient descent),
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,76,Move against the gradient to minimize loss,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,82,Use the trained model to predict labels of X,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,84,Forward pass:,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,97,Convert the nominal y values to binary,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,102,MLP,
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,114,Reduce dimension to two using PCA and plot the results,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,24,gradient w.r.t y_pred,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,29,w.r.t y_pred,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,56,Number of trees,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,57,Step size for weight update,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,58,The minimum n of sampels to justify split,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,59,Minimum variance reduction to continue,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,60,Maximum depth for tree,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,64,Log loss for classification,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,67,Initialize regression trees,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,92,Make predictions,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,94,Estimate gradient and update prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,100,Turn into probability distribution (Softmax),
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,102,Set label to the value that maximizes probability,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,42,Prior parameters,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,48,Allows for simulation from the scaled inverse chi squared,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,49,distribution. Assumes the variance is distributed according to,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,50,this distribution.,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,51,Reference:,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,52,https://en.wikipedia.org/wiki/Scaled_inverse_chi-squared_distribution,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,60,If polynomial transformation,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,68,Least squares approximate of beta,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,71,The posterior parameters can be determined analytically since we assume,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,72,conjugate priors for the likelihoods.,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,74,Normal prior / likelihood => Normal posterior,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,77,Scaled inverse chi-squared prior / likelihood => Scaled inverse chi-squared posterior,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,82,Simulate parameter values for n_draws,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,87,Save parameter draws,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,90,Select the mean of the simulated variables as the ones used to make predictions,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,93,Lower and upper boundary of the credible interval,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,101,If polynomial transformation,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,106,If the lower and upper boundaries for the 95%,
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,107,equal tail interval should be returned,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,40,"Initialize weights between [-1/sqrt(N), 1/sqrt(N)]",
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,46,Calculate outputs,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,49,Calculate the loss gradient w.r.t the input of the activation function,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,51,Calculate the gradient of the loss with respect to each weight,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,54,Update weights,
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,58,Use the trained model to predict labels of X,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,9,Hide cvxopt output,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,45,Set gamma to 1/n_features by default,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,49,Initialize kernel method with parameters,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,55,Calculate kernel matrix,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,61,Define the quadratic optimization problem,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,78,Solve the quadratic optimization problem using cvxopt,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,81,Lagrange multipliers,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,84,Extract support vectors,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,85,Get indexes of non-zero lagr. multipiers,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,87,Get the corresponding lagr. multipliers,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,89,Get the samples that will act as support vectors,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,91,Get the corresponding labels,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,94,Calculate intercept with first support vector,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,102,Iterate through list of samples and make predictions,
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,105,Determine the label of the sample by the support vectors,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,44,Square loss for regression,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,45,Log loss for classification,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,50,Initialize regression trees,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,66,Update y prediction,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,72,Make predictions,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,79,Turn into probability distribution,
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,81,Set label to the value that maximizes probability,
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,24,Determine the class of each sample,
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,26,Sort the training samples by their distance to the test sample and get the K nearest,
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,28,Extract the labels of the K nearest neighboring training samples,
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,30,Label sample as the most common class label,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,42,Mutation of weight with probability self.mutation_rate,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,54,The child inherits both weights W and bias weights w0,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,65,Perform crossover,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,69,Perform crossover between the individuals' neuron weights,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,91,The 40% highest fittest individuals will be selected for the next generation,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,93,The fittest 60% of the population will be selected as parents to form offspring,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,97,Determine the fitness of the individuals in the population,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,100,Sort population by fitness,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,104,Get the individual with the highest fitness,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,109,The 'winners' are selected for the next generation,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,113,The probability that a individual will be selected as a parent is proportionate to its fitness,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,115,Select parents according to probabilities (without replacement to preserve diversity),
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,118,Perform crossover to produce offspring,
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,120,Save mutated offspring for next population,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,4,Optimizers for models that use gradient based methods for finding the,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,5,weights that minimizes the loss.,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,6,A great resource for understanding these methods:,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,7,http://sebastianruder.com/optimizing-gradient-descent/index.html,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,16,If not initialized,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,19,Use momentum if set,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,21,Move against the gradient to minimize loss,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,31,Calculate the gradient of the loss a bit further down the slope from w,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,33,Initialize on first update,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,38,Move against the gradient to minimize loss,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,44,Sum of squares of the gradients,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,48,If not initialized,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,51,Add the square of the gradient of the loss function at w,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,53,Adaptive gradient with higher learning rate for sparse data,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,58,Running average of squared parameter updates,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,59,Running average of the squared gradient of w,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,60,Parameter update,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,65,If not initialized,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,71,Update average of gradients at w,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,77,Adaptive learning rate,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,80,Calculate the update,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,83,Update the running average of w updates,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,91,Running average of the square gradients at w,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,96,If not initialized,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,102,Divide the learning rate for a weight by a running average of the magnitudes of recent,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,103,gradients for that weight,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,112,Decay rates,
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,117,If not initialized,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,61,Initialize the weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,65,Weight optimizers,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,77,Save weights used during forwards pass,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,81,Calculate gradient w.r.t layer weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,85,Update the layer weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,89,Return accumulated gradient for next layer,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,90,Calculated based on the weights used during the forward pass,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,124,Weight of the previous state,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,125,Weight of the output,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,126,Weight of the input,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,130,Initialize the weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,136,Weight optimizers,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,148,Save these values for use in backprop.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,153,Set last time step to zero for calculation of the state_input at time step zero,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,156,Input to state_t is the current input and output of previous states,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,166,Variables where we save the accumulated gradient w.r.t each parameter,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,170,The gradient w.r.t the layer input.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,171,Will be passed on to the previous layer in the network,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,174,Back Propagation Through Time,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,176,Update gradient w.r.t V at time step t,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,178,Calculate the gradient w.r.t the state input,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,180,Gradient w.r.t the layer input,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,182,Update gradient w.r.t W and U by backprop. from time step t for at most,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,183,self.bptt_trunc number of time steps,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,187,Calculate gradient w.r.t previous state,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,190,Update weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,228,Initialize the weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,234,Weight optimizers,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,244,Turn image shape into column shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,245,(enables dot product between input and weights),
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,247,Turn weights into column shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,249,Calculate output,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,251,"Reshape into (n_filters, out_height, out_width, batch_size)",
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,253,Redistribute axises so that batch size comes first,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,257,Reshape accumulated gradient into column shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,261,Take dot product between column shaped accum. gradient and column shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,262,layer input to determine the gradient at the layer with respect to layer weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,264,The gradient with respect to bias terms is the sum similarly to in Dense layer,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,267,Update the layers weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,271,Recalculate the gradient which will be propogated back to prev. layer,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,273,Reshape from column shape to image shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,301,Initialize the parameters,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,304,parameter optimizers,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,313,Initialize running mean and variance if first run,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,327,Statistics saved for backward pass,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,338,Save parameters used during the forward pass,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,341,If the layer is trainable the parameters are updated,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,352,The gradient of the loss with respect to the layer inputs (use weights and statistics from forward pass),
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,384,MaxPool or AveragePool specific method,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,397,MaxPool or AveragePool specific method,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,536,Repeat each axis as specified by size,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,541,Down sample input to previous shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,644,Method which calculates the padding based on the specified output shape and the,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,645,shape of the filters,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,648,No padding,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,651,Pad so that the output shape is the same as input shape (given that stride=1),
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,655,Derived from:,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,656,output_height = (height + pad_h - filter_height) / stride + 1,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,657,In this case output_height = height and stride = 1. This gives the,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,658,expression for the padding below.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,667,Reference: CS231n Stanford,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,669,First figure out what the size of the output should be,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,689,Method which turns the image shaped input to column shape.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,690,Used during the forward pass.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,691,Reference: CS231n Stanford,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,697,Add padding to the image,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,700,Calculate the indices where the dot products are to be applied between weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,701,and the image,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,704,Get content from image at those indices,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,707,Reshape content into column shape,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,713,Method which turns the column shaped input to image shape.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,714,Used during the backward pass.,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,715,Reference: CS231n Stanford,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,723,Calculate the indices where the dot products are applied between weights,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,724,and the image,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,729,Add column content to the images at the indices,
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,732,Return image without padding,
ML-From-Scratch/mlfromscratch/deep_learning/loss_functions.py,29,Avoid division by zero,
ML-From-Scratch/mlfromscratch/deep_learning/loss_functions.py,37,Avoid division by zero,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,41,If this is not the first layer added then set the input shape,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,42,to the output shape of the last added layer,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,46,If the layer has weights that needs to be initialized,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,50,Add layer to the network,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,66,Calculate the gradient of the loss function wrt y_pred,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,68,Backpropagate. Update weights,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,104,Print model name,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,106,Network input shape (first layer's input shape),
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,108,Iterate through network and get each layer's configuration,
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,117,Print network configuration table,
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,3,Collection of activation functions,
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,4,Reference: https://en.wikipedia.org/wiki/Activation_function,
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,57,"Reference : https://arxiv.org/abs/1706.02515,",
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,58,https://github.com/bioinf-jku/SNNs/blob/master/SelfNormalizingNetworks_MLP_MNIST.ipynb,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,36,Initialize the environment,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,46,Choose action randomly,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,49,Take action with highest predicted utility given state,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,56,Make sure we restrict memory size to specified limit,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,61,Select states and new states from replay,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,65,Predict the expected utility of current state and new state,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,73,Construct training set,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,79,If we're done the utility is simply the reward of executing action a in,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,80,"state s, otherwise we add the expected maximum future reward as well",
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,100,Take a step,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,105,Sample replay batch from memory,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,109,Construct training set from replay,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,112,Learn control policy,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,123,Reduce the epsilon parameter,
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,133,"self.env = gym.wrappers.Monitor(self.env, '/tmp/cartpole-experiment-1', force=True)",
ML-From-Scratch/mlfromscratch/examples/gaussian_mixture_model.py,14,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/gaussian_mixture_model.py,17,Cluster the data,
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,13,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,19,"fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,32,Training error plot,
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,47,Color map,
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,50,Plot the results,
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,14,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,20,"Time. Fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,21,Temperature. Reduce to one-dim,
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,31,Color map,
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,38,Plot the results,
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,39,Plot the results,
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,23,Model builder,
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,33,Print the model summary of a individual in the population,
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,67,Reduce dimension to 2D using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,12,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,17,Three -> two classes,
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,23,Fit and predict using LDA,
ML-From-Scratch/mlfromscratch/examples/apriori.py,7,Demo transaction set,
ML-From-Scratch/mlfromscratch/examples/apriori.py,8,Example 2: https://en.wikipedia.org/wiki/Apriori_algorithm,
ML-From-Scratch/mlfromscratch/examples/apriori.py,23,Get and print the frequent itemsets,
ML-From-Scratch/mlfromscratch/examples/apriori.py,27,Get and print the rules,
ML-From-Scratch/mlfromscratch/examples/multi_class_lda.py,9,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/multi_class_lda.py,14,Project the data onto the 2 primary components,
ML-From-Scratch/mlfromscratch/examples/naive_bayes.py,22,Reduce dimension to two using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,4,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,9,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,12,Cluster the data using K-Medoids,
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,16,Project the data onto the 2 primary principal components,
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,13,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,19,"fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,33,Training error plot,
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,48,Color map,
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,51,Plot the results,
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,6,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,13,Load dataset,
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,29,Reduce dimension to two using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/deep_q_network.py,18,Model builder,
ML-From-Scratch/mlfromscratch/examples/adaboost.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/adaboost.py,20,"Change labels to {-1, 1}",
ML-From-Scratch/mlfromscratch/examples/adaboost.py,27,Adaboost classification with 5 weak classifiers,
ML-From-Scratch/mlfromscratch/examples/adaboost.py,35,Reduce dimensions to 2d using pca and plot the results,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,19,Select the samples of the digit 2,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,22,Limit dataset to 500 samples,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,29,Training error plot,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,37,Get the images that were reconstructed during training,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,40,Plot the reconstructed images during the first iteration,
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,52,Plot the images during the last iteration,
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,22,Training error plot,
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,37,Color map,
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,40,Plot the results,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,13,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,19,"fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,26,Finding regularization constant using cross validation,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,46,Print the mean squared error,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,49,Save reg. constant that gave lowest error,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,54,Make final prediction,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,66,Color map,
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,69,Plot the results,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_classifier.py,6,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,10,Demo of how to reduce the dimensionality of the data to two dimension,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,11,and plot the results.,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,13,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,18,Project the data onto the 2 primary principal components,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,28,Plot the different class distributions,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,35,Add a legend,
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,38,Axis labels,
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,6,Demo transaction set,
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,7,Example:,
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,8,https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Frequent_Pattern_Mining/The_FP-Growth_Algorithm,
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,33,Get and print the frequent itemsets,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,8,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,23,----------,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,24,Conv Net,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,25,----------,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,33,Convert to one-hot encoding,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,38,"Reshape X to (n_samples, channels, height, width)",
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,67,Training and validation error plot,
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,83,Reduce dimension to 2D using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/k_means.py,10,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/k_means.py,13,Cluster the data using K-Means,
ML-From-Scratch/mlfromscratch/examples/k_means.py,17,Project the data onto the 2 primary principal components,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,17,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,23,"Time. Fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,24,Insert bias term,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,25,Temperature. Reduce to one-dim,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,35,Color map,
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,42,Plot the results,
ML-From-Scratch/mlfromscratch/examples/decision_tree_classifier.py,8,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/dbscan.py,8,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/dbscan.py,13,Load the dataset,
ML-From-Scratch/mlfromscratch/examples/dbscan.py,16,Cluster the data using DBSCAN,
ML-From-Scratch/mlfromscratch/examples/dbscan.py,20,Project the data onto the 2 primary principal components,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,7,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,21,-----,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,22,MLP,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,23,-----,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,29,Convert to one-hot encoding,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,60,Training and validation error plot,
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,73,Reduce dimension to 2D using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/demo.py,25,...........,
ML-From-Scratch/mlfromscratch/examples/demo.py,26,LOAD DATA,
ML-From-Scratch/mlfromscratch/examples/demo.py,27,...........,
ML-From-Scratch/mlfromscratch/examples/demo.py,33,"Change labels to {0, 1}",
ML-From-Scratch/mlfromscratch/examples/demo.py,41,..........................,
ML-From-Scratch/mlfromscratch/examples/demo.py,42,DIMENSIONALITY REDUCTION,
ML-From-Scratch/mlfromscratch/examples/demo.py,43,..........................,
ML-From-Scratch/mlfromscratch/examples/demo.py,45,Reduce to 5 dimensions,
ML-From-Scratch/mlfromscratch/examples/demo.py,49,..........................,
ML-From-Scratch/mlfromscratch/examples/demo.py,50,TRAIN / TEST SPLIT,
ML-From-Scratch/mlfromscratch/examples/demo.py,51,..........................,
ML-From-Scratch/mlfromscratch/examples/demo.py,53,"Rescaled labels {-1, 1}",
ML-From-Scratch/mlfromscratch/examples/demo.py,57,.......,
ML-From-Scratch/mlfromscratch/examples/demo.py,58,SETUP,
ML-From-Scratch/mlfromscratch/examples/demo.py,59,.......,
ML-From-Scratch/mlfromscratch/examples/demo.py,80,........,
ML-From-Scratch/mlfromscratch/examples/demo.py,81,TRAIN,
ML-From-Scratch/mlfromscratch/examples/demo.py,82,........,
ML-From-Scratch/mlfromscratch/examples/demo.py,109,.........,
ML-From-Scratch/mlfromscratch/examples/demo.py,110,PREDICT,
ML-From-Scratch/mlfromscratch/examples/demo.py,111,.........,
ML-From-Scratch/mlfromscratch/examples/demo.py,126,..........,
ML-From-Scratch/mlfromscratch/examples/demo.py,127,ACCURACY,
ML-From-Scratch/mlfromscratch/examples/demo.py,128,..........,
ML-From-Scratch/mlfromscratch/examples/demo.py,131,Rescaled {-1 1},
ML-From-Scratch/mlfromscratch/examples/demo.py,134,Categorical,
ML-From-Scratch/mlfromscratch/examples/demo.py,138,.......,
ML-From-Scratch/mlfromscratch/examples/demo.py,139,PLOT,
ML-From-Scratch/mlfromscratch/examples/demo.py,140,.......,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,12,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,18,"fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,25,Prior parameters,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,26,- Weights are assumed distr. according to a Normal distribution,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,27,- The variance of the weights are assumed distributed according to,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,28,a scaled inverse chi-squared distribution.,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,29,High prior uncertainty!,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,30,Normal,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,33,Scaled inverse chi-squared,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,37,The credible interval,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,52,Get prediction line,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,55,Print the mean squared error,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,58,Color map,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,61,Plot the results,
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,73,"plt.legend((m1, m2), (""Training data"", ""Test data""), loc='lower right')",
ML-From-Scratch/mlfromscratch/examples/perceptron.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/perceptron.py,18,One-hot encoding of nominal y-values,
ML-From-Scratch/mlfromscratch/examples/perceptron.py,23,Perceptron,
ML-From-Scratch/mlfromscratch/examples/perceptron.py,37,Reduce dimension to two using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/support_vector_machine.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/support_vector_machine.py,26,Reduce dimension to two using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,5,Import helper functions,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,13,Load temperature data,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,19,"fraction of the year [0, 1]",
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,26,Finding regularization constant using cross validation,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,46,Print the mean squared error,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,49,Save reg. constant that gave lowest error,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,54,Make final prediction,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,67,Color map,
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,70,Plot the results,
ML-From-Scratch/mlfromscratch/examples/k_nearest_neighbors.py,23,Reduce dimensions to 2d using pca and plot the results,
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,23,Model builder,
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,33,Print the model summary of a individual in the population,
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,56,Reduce dimension to 2D using PCA and plot the results,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,27,Mark endpoint as 1,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,40,Mark endpoint as 1,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,46,Model definition,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,53,Print a problem instance and the correct solution,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,63,Predict labels of the test data,
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,70,Print a problem instance and the correct solution,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,51,dimension,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,71,Calculate probabilities of X belonging to the different clusters,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,75,Determine responsibility as P(X|y)*P(y)/P(X),
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,77,Assign samples to cluster that has largest probability,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,79,Save value for convergence check,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,84,Iterate through clusters and recalculate mean and covariance,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,92,Update weights,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,102,"print (""Likelihood update: %s (tol: %s)"" % (diff, self.tolerance))",
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,107,Initialize the gaussians randomly,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,110,Run EM until convergence or for max iterations,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,112,E-step,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,113,M-step,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,115,Check convergence,
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,119,Make new assignments and return them,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,31,List of freqeuent itemsets,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,32,List of transactions,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,47,Find frequent items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,59,Find all combinations of size k-1 in candidate,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,60,"E.g [1,2,3] => [[1,2],[1,3],[2,3]]",
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,63,t - is tuple. If size == 1 get the element,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,77,Valid if every element but the last are the same,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,78,and the last element in itemset1 is smaller than the last,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,79,in itemset2,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,88,JOIN: Add the last element in itemset2 to itemset1 to,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,89,create a new candidate,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,94,PRUNE: Check if any subset of candidate have been determined,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,95,to be infrequent,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,105,If items is in fact only one item,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,108,Iterate through list of items and make sure that,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,109,all items are in the transaction,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,118,Get all unique items in the transactions,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,120,Get the frequent items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,123,Generate new candidates from last added frequent itemsets,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,125,Get the frequent itemsets among those candidates,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,128,If there are no frequent itemsets we're done,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,132,Add them to the total list of frequent itemsets and start over,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,135,Flatten the array and return every frequent itemset,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,146,Get all combinations of sub-itemsets of size k - 1 from itemset,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,147,"E.g [1,2,3] => [[1,2],[1,3],[2,3]]",
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,151,itertools.combinations returns tuples => convert to list,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,154,"Calculate the confidence as sup(A and B) / sup(B), if antecedent",
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,155,is B in an itemset of A and B,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,158,The concequent is the initial_itemset except for antecedent,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,160,If single item => get item,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,165,Create new rule,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,173,If there are subsets that could result in rules,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,174,recursively add rules from subsets,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,182,Only consider itemsets of size >= 2 items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,188,Remove empty values,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,53,For each cluster,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,57,Add distance between sample and medoid as cost,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,71,One prediction for each sample,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,81,Initialize medoids randomly,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,83,Assign samples to closest medoids,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,86,Calculate the initial cost (total distance between samples and,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,87,corresponding medoids),
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,90,Iterate until we no longer have a cheaper cost,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,95,Get all non-medoid samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,97,Calculate the cost when swapping medoid and samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,99,Swap sample with the medoid,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,102,Assign samples to new medoids,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,104,Calculate the cost with the new set of medoids,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,107,If the swap gives us a lower cost we save the medoids and cost,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,111,If there was a swap that resultet in a lower cost we save the,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,112,resulting medoids from the best swap and the new cost,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,116,Else finished,
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,121,Return the samples cluster indices as labels,
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,39,Bias visible,
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,40,Bias hidden,
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,52,Positive phase,
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,57,Negative phase,
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,70,Reconstruct a batch of images from the training set,
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,17,"Where (eigenvector[:,0] corresponds to eigenvalue[0])",
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,20,Sort the eigenvalues and corresponding eigenvectors from largest,
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,21,to smallest eigenvalue and select the first n_components,
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,26,Project the data onto principal components,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,24,Build the discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,27,Build the generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,30,Build the combined model,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,93,Rescale -1 to 1,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,100,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,101,Train Discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,102,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,106,Select a random half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,110,Sample noise to use as generator input,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,113,Generate a half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,119,Train the discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,126,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,127,Train Generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,128,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,130,We only want to train the generator for the combined model,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,133,Sample noise and use as generator input,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,136,The generator wants the discriminator to label the generated samples as valid,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,139,Train the generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,142,Display the progress,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,145,If at save interval => save generated image samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,154,Rescale images 0 - 1 (from -1 to 1),
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,31,Build the discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,34,Build the generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,37,Build the combined model,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,86,"Rescale [-1, 1]",
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,93,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,94,Train Discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,95,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,99,Select a random half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,103,Sample noise to use as generator input,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,106,Generate a half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,109,"Valid = [1, 0], Fake = [0, 1]",
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,113,Train the discriminator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,120,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,121,Train Generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,122,---------------------,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,124,We only want to train the generator for the combined model,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,127,Sample noise and use as generator input,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,130,The generator wants the discriminator to label the generated samples as valid,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,133,Train the generator,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,136,Display the progress,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,139,If at save interval => save generated image samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,144,Grid size,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,146,Generate images and reshape to image shape,
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,149,Rescale images 0 - 1,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,8,'Value' of the item,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,10,Number of times the item occurs in a,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,11,transaction,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,13,Child nodes in the FP Growth Tree,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,31,The root of the initial FP Growth Tree,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,33,Prefixes of itemsets in the FP Growth Tree,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,37,Count the number of transactions that contains item.,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,51,Get all unique items in the transactions,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,59,Sort by support - Highest to lowest,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,62,Only return the items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,69,Create new node as the first item in children list,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,72,If parent already contains item => increase the support,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,78,Execute _insert_tree on the rest of the children list,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,79,from the new node,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,84,Get frequent items sorted by support,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,88,Construct the root of the FP Growth tree,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,91,Remove items that are not frequent according to,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,92,unique_frequent_items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,126,If the current node is a prefix to the itemset,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,127,add the current prefixes value as prefix to the itemset,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,136,Recursive call with child as new node. Add the child item as potential,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,137,prefix.,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,151,Calculate new frequent items from the conditional database,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,152,of suffix,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,159,Output new frequent itemset as the suffix added to the frequent,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,160,items,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,163,Find larger frequent itemset by finding prefixes,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,164,of the frequent items in the FP Growth Tree for the conditional,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,165,database.,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,168,If no suffix (first run),
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,171,Determine prefixes to itemset,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,175,Build new conditional database,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,178,If support = 4 => add 4 of the corresponding prefix set,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,181,Create new suffix,
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,188,Build the FP Growth Tree,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,64,One prediction for each sample,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,74,Initialize centroids as k random samples from X,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,77,Iterate until convergence or for max iterations,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,79,Assign samples to closest centroids (create clusters),
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,81,Save current centroids for convergence check,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,83,Calculate new centroids from the clusters,
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,85,If no centroids have changed => convergence,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,38,Iterate through neighbors,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,42,Fetch the sample's distant neighbors (neighbors of neighbor),
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,44,Make sure the neighbor's neighbors are more than min_samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,45,(If this is true the neighbor is a core point),
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,47,Expand the cluster from the neighbor,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,50,Add expanded cluster to this cluster,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,53,If the neighbor is not a core point we only add the neighbor point,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,60,Set default value to number of clusters,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,61,Will make sure all outliers have same cluster label,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,68,DBSCAN,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,75,Iterate through samples and expand clusters from them,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,76,if they have more neighbors than self.min_samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,82,If core point => mark as visited,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,84,Sample has more neighbors than self.min_samples => expand,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,85,cluster from sample,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,88,Add cluster to list of clusters,
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,91,Get the resulting cluster labels,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,29,Select random letters as new individual,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,37,Calculate loss as the alphabetical distance between,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,38,the characters in the individual and the target string,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,53,Make change with probability mutation_rate,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,56,Return mutated individual as string,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,61,Select random crossover point,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,68,Initialize new population,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,77,If we have found individual which matches the target => Done,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,81,Set the probability that the individual should be selected as a parent,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,82,proportionate to the individual's fitness.,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,85,Determine the next generation,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,88,Select two parents randomly according to probabilities,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,90,Perform crossover to produce offspring,
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,92,Save mutated offspring for next generation,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,25,The dimension of the data embedding,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,74,"Rescale [-1, 1]",
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,79,Select a random half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,83,Train the Autoencoder,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,86,Display the progress,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,89,If at save interval => save generated image samples,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,94,Grid size,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,95,Select a random half batch of images,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,98,Generate images and reshape to image shape,
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,101,Rescale images 0 - 1,
