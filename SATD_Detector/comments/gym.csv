file path,line #,comment,satd
gym/setup.py,4,"Don't import gym module here, since deps may not be installed",
gym/setup.py,8,Environment-specific dependencies.,
gym/setup.py,17,Meta dependency groups.,
gym/bin/render.py,1,!/usr/bin/env python3,
gym/,36,DEPRECATED:,
gym/,6,Local errors,
gym/,65,API errors,
gym/,94,Python 2,
gym/,96,Python 3,
gym/,120,Video errors,
gym/,128,Wrapper errors,
gym/,141,Vectorized environments errors,
gym/,33,Set this in SOME subclasses,
gym/,38,Set these in ALL subclasses,
gym/,154,propagate exception,
gym/,168,Enforce that each GoalEnv uses a Goal-compatible observation space.,
gym/,63,Explicitly fetch all monitors first so that they can't disappear while,
gym/,64,we iterate. cf. http://stackoverflow.com/a/12429620,
gym/,53,Adapted from https://svn.python.org/projects/python/tags/r32/Lib/random.py,
gym/,67,TODO: don't hardcode sizeof_int here,
gym/,80,Special case 0,
gym/,1,Based on http://stackoverflow.com/questions/2333872/atomic-writing-to-file-with-python,
gym/,6,We would ideally atomically replace any existing file with the new,
gym/,7,"version. However, on Windows there's no Python-only solution prior",
gym/,8,to Python 3.3. (This library includes a C extension to do so:,
gym/,9,https://pypi.python.org/pypi/pyosreplace/0.1.),
gym/,10,,
gym/,11,"Correspondingly, we make a best effort, but on Python < 3.3 use a",
gym/,12,replace method which could result in the file temporarily,
gym/,13,disappearing.,
gym/,16,Python 3.3 and up have a native `replace` method,
gym/,20,"TODO: on Windows, this will raise if the file is in use,",
gym/,21,which is possible. We'll need to make this more robust over,
gym/,22,time.,
gym/,29,POSIX rename() is always atomic,
gym/,118,process pygame events,
gym/,120,"test events, set key states",
gym/,5,These submodules should not have any import-time dependencies.,
gym/,6,We want this since we use `utils` during our import-time sanity checks,
gym/,7,that verify that our dependencies are actually present.,
gym/,40,The observation and action spaces of a single environment are,
gym/,41,kept in separate properties,
gym/,66,"CubeCrash-v0 - observation_space: Box(40, 32, 3)",
gym/,68,"MemorizeDigits-v0 - observation_space: Box(24, 32, 3)",
gym/,16,"Special case: if rhs is a list of scalars, lhs must be an np.ndarray",
gym/,190,"CubeCrash-v0 - observation_space: Box(40, 32, 3)",
gym/,192,"MemorizeDigits-v0 - observation_space: Box(24, 32, 3)",
gym/,54,Assert the length of the array,
gym/,56,Assert the data type,
gym/,11,"This looks like a pretty trivial, but given our usage of",
gym/,12,"__new__, it's worth having.",
gym/,56,Make sure we are testing the right environment for the test.,
gym/,62,The wrapper should only add one observation.,
gym/,82,Check that the added space item is consistent with the added observation.,
gym/,62,buffer of most recent two observations for max pooling,
gym/,108,NoopReset,
gym/,125,more efficient in-place pooling,
gym/,8,mountaincar: action-based rewards,
gym/,55,Make sure we are testing the right environment for the test.,
gym/,70,Check that the added space item is consistent with the added observation.,
gym/,10,TODO: use perf_counter when gym removes Python 2 support,
gym/,34,"ALE gray scale is slightly different, but no more than by one shade",
gym/,70,Make sure that now keys in the `pixel_keys` overlap with,
gym/,71,`observation_keys`,
gym/,85,Extend observation space with pixels.,
gym/,11,use case #1: scale,
gym/,29,use case #2: clip,
gym/,48,use case #3: sign,
gym/,79,Check on whether we need to clear anything,
gym/,93,We use the 'openai-gym' prefix to determine if a file is,
gym/,94,ours,
gym/,113,"Give it a very distiguished name, since we need to pick it",
gym/,114,up from the filesystem later.,
gym/,118,We need to write relative paths here since people may,
gym/,119,move the training_dir around. It would be cleaner to,
gym/,120,already have the basenames rather than basename'ing,
gym/,121,"manually, but this works for now.",
gym/,140,Stop tracking this for autoclose,
gym/,163,"For envs with BlockingReset wrapping VNCEnv, this observation will be the first one of the new episode",
gym/,168,Record stats,
gym/,170,Record video,
gym/,182,Reset the stat count,
gym/,187,Bump *after* all reset activity has finished,
gym/,193,Close any existing video recorder,
gym/,197,Start recording the next video.,
gym/,198,,
gym/,199,TODO: calculate a more correct 'episode_id' upon merge,
gym/,225,Make sure we've closed up shop when garbage collecting,
gym/,265,This method gets used for a sanity check in scoreboard/api.py. It's,
gym/,266,not intended for use outside of the gym codebase.,
gym/,292,Load up stats + video files,
gym/,300,Make these paths absolute again,
gym/,333,"so empty file doesn't mess up results, due to null initial_reset_timestamp",
gym/,338,Recent addition,
gym/,340,Keep track of where each episode came from.,
gym/,361,"TODO training_dir isn't used except for error messages, clean up the layering",
gym/,30,"the edges of the numbers do not render quite the same in the grayscale, so we ignore them",
gym/,32,the paddle also do not render quite the same,
gym/,41,arbitrarily chosen number for stepping into env. and ensuring all observations are in the required range,
gym/,36,Don't bother setting anything else if not enabled,
gym/,46,"Whoops, turns out we shouldn't be enabled after all",
gym/,59,"Base path given, append ext",
gym/,62,"Otherwise, just generate a unique filename",
gym/,72,"Touch the file in any case, so we know it's present. (This",
gym/,73,corrects for platform platform differences. Using ffmpeg on,
gym/,74,"OS X, the file is precreated, but not on Linux.",
gym/,79,lazily start the process,
gym/,82,Dump metadata,
gym/,107,Indicates a bug in the environment: don't want to raise,
gym/,108,an error here.,
gym/,128,"No frames captured. Set metadata, and remove the empty output file.",
gym/,135,"If broken, get rid of the output file, otherwise we'd leak it.",
gym/,139,"Might have crashed before even starting the output file, don't try to remove in that case.",
gym/,203,frame_duration = float(1) / self.frames_per_sec,
gym/,206,Turn frames into events: clear screen beforehand,
gym/,207,https://rosettacode.org/wiki/Terminal_control/Clear_the_screen#Python,
gym/,208,https://rosettacode.org/wiki/Terminal_control/Cursor_positioning#Python,
gym/,210,Decode the bytes as UTF-8 since JSON may only contain UTF-8,
gym/,213,Calculate frame size from the largest frames.,
gym/,214,Add some padding since we'll get cut off otherwise.,
gym/,225,could add some env metadata here,
gym/,240,"Frame shape should be lines-first, so w and h are swapped",
gym/,271,suppress warnings,
gym/,274,input,
gym/,279,"this used to be /dev/stdin, which is not Windows-friendly",
gym/,281,output,
gym/,290,setsid not present on Windows,
gym/,19,experimental addition,
gym/,77,We write the type at the beginning of the episode. If a user,
gym/,78,"changes the type, it's more natural for it to apply next",
gym/,79,time the user calls reset().,
gym/,40,Promote list to array for contains check,
gym/,41,"if nvec is uint32 and space dtype is uint32, then 0 <= x < self.nvec guarantees that x",
gym/,42,is within correct bounds for space dtype (even though x does not have to be unsigned),
gym/,10,"takes about 300-400ms to import, so we load lazily",
gym/,38,"By default, assume identity is JSONable",
gym/,43,"By default, assume identity is JSONable",
gym/,52,Boolean arrays which indicate the interval type for each coordinate,
gym/,86,Masking arrays which classify the coordinates according to interval,
gym/,87,type,
gym/,94,Vectorized sampling by interval type,
gym/,114,Promote list to array for contains check,
gym/,45,"None for shape and dtype, since it'll require special handling",
gym/,70,serialize as dict-repr of vectors,
gym/,26,Promote list to tuple for contains check,
gym/,34,serialize as list-repr of tuple of vectors,
gym/,30,Promote list to array for contains check,
gym/,1,note: ujson fails this test due to float equality,
gym/,7,"This format is true today, but it's *not* an official spec.",
gym/,8,"[username/](env-name)-v(version)    env-name is group 1, version is group 2",
gym/,9,,
gym/,10,2016-10-31: We're experimentally expanding the environment ID format,
gym/,11,to include an optional username.,
gym/,61,Make the environment aware of which spec it came from.,
gym/,88,We used to have people override _reset/_step rather than,
gym/,89,reset/step. Set _gym_disable_underscore_compat = True on,
gym/,90,your environment if you use these methods and don't want,
gym/,91,compatibility code to be invoked.,
gym/,107,catch ImportError for python2.7 compatibility,
gym/,120,Parse the env name and check to see if it matches the non-version,
gym/,121,part of a valid env (could also check the exact number here),
gym/,135,Have a global registry,
gym/,3,Algorithmic,
gym/,4,----------------------------------------,
gym/,50,Classic,
gym/,51,----------------------------------------,
gym/,94,Box2d,
gym/,95,----------------------------------------,
gym/,132,Toy Text,
gym/,133,----------------------------------------,
gym/,155,optimum = .8196,
gym/,163,optimum = 1,
gym/,186,optimum = 8.46,
gym/,202,Mujoco,
gym/,203,----------------------------------------,
gym/,205,2D,
gym/,335,Robotics,
gym/,336,----------------------------------------,
gym/,348,Fetch,
gym/,377,Hand,
gym/,455,"Alias for ""Full""",
gym/,505,"Alias for ""Full""",
gym/,555,"Alias for ""Full""",
gym/,577,Atari,
gym/,578,----------------------------------------,
gym/,580,"# print ', '.join([""'{}'"".format(name.split('.')[0]) for name in atari_py.list_games()])",
gym/,591,space_invaders should yield SpaceInvaders-v0 and SpaceInvaders-ram-v0,
gym/,598,ElevatorAction-ram-v0 seems to yield slightly,
gym/,599,non-deterministic observations about 10% of the time. We,
gym/,600,"should track this down eventually, but for now we just",
gym/,601,mark it as nondeterministic.,
gym/,620,Standard Deterministic (as in the original DeepMind paper),
gym/,626,Use a deterministic frame skip.,
gym/,646,A frameskip of 1 means we get every frame,
gym/,651,"No frameskip. (Atari has no entropy source, so these are",
gym/,652,deterministic environments.),
gym/,656,A frameskip of 1 means we get every frame,
gym/,662,Unit test,
gym/,663,---------,
gym/,6,Unit test environment for CNNs and CNN+RNN algorithms.,
gym/,7,Looks like this (RGB observations):,
gym/,8,,
gym/,9,---------------------------,
gym/,10,|                           |,
gym/,11,|                           |,
gym/,12,|                           |,
gym/,13,|          **               |,
gym/,14,|          **               |,
gym/,15,|                           |,
gym/,16,|                           |,
gym/,17,|                           |,
gym/,18,|                           |,
gym/,19,|                           |,
gym/,20,========     ==============,
gym/,21,,
gym/,22,Goal is to go through the hole at the bottom. Agent controls square using Left-Nop-Right actions.,
gym/,23,"It falls down automatically, episode length is a bit less than FIELD_H",
gym/,24,,
gym/,25,CubeCrash-v0                    # shaped reward,
gym/,26,CubeCrashSparse-v0              # reward 0 or 1 at the end,
gym/,27,CubeCrashScreenBecomesBlack-v0  # for RNNs,
gym/,28,,
gym/,29,"To see how it works, run:",
gym/,30,,
gym/,31,python examples/agents/keyboard_agent.py CubeCrashScreen-v0,
gym/,51,Makes env too hard,
gym/,6,Unit test environment for CNNs.,
gym/,7,Looks like this (RGB observations):,
gym/,8,,
gym/,9,---------------------------,
gym/,10,|                           |,
gym/,11,|         ******            |,
gym/,12,|         ******            |,
gym/,13,|       **      **          |,
gym/,14,|       **      **          |,
gym/,15,|               **          |,
gym/,16,|               **          |,
gym/,17,|           ****            |,
gym/,18,|           ****            |,
gym/,19,|       ****                |,
gym/,20,|       ****                |,
gym/,21,|       **********          |,
gym/,22,|       **********          |,
gym/,23,|                           |,
gym/,24,---------------------------,
gym/,25,,
gym/,26,Agent should hit action 2 to gain reward. Catches off-by-one errors in your agent.,
gym/,27,,
gym/,28,"To see how it works, run:",
gym/,29,,
gym/,30,python examples/agents/keyboard_agent.py MemorizeDigits-v0,
gym/,15,"Easiest continuous control task to learn from pixels, a top-down racing environment.",
gym/,16,"Discrete control is reasonable in this environment as well, on/off discretization is",
gym/,17,fine.,
gym/,18,,
gym/,19,State consists of STATE_W x STATE_H pixels.,
gym/,20,,
gym/,21,"Reward is -0.1 every frame and +1000/N for every track tile visited, where N is",
gym/,22,"the total number of tiles visited in the track. For example, if you have finished in 732 frames,",
gym/,23,your reward is 1000 - 0.1*732 = 926.8 points.,
gym/,24,,
gym/,25,Game is solved when agent consistently gets 900+ points. Track generated is random every episode.,
gym/,26,,
gym/,27,"Episode finishes when all tiles are visited. Car also can go outside of PLAYFIELD, that",
gym/,28,"is far off the track, then it will get -100 and die.",
gym/,29,,
gym/,30,Some indicators shown at the bottom of the window and the state RGB buffer. From,
gym/,31,"left to right: true speed, four ABS sensors, steering wheel position and gyroscope.",
gym/,32,,
gym/,33,"To play yourself (it's rather fast for humans), type:",
gym/,34,,
gym/,35,python gym/envs/box2d/car_racing.py,
gym/,36,,
gym/,37,"Remember it's powerful rear-wheel drive car, don't press accelerator and turn at the",
gym/,38,same time.,
gym/,39,,
gym/,40,Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.,
gym/,42,less than Atari 160x192,
gym/,49,Track scale,
gym/,50,Track is heavily morphed circle with this radius,
gym/,51,Game over boundary,
gym/,52,Frames per second,
gym/,53,Camera zoom,
gym/,54,Set to False for fixed view (don't use zoom),
gym/,94,"print tile.road_friction, ""ADD"", len(obj.tiles)",
gym/,101,"print tile.road_friction, ""DEL"", len(obj.tiles) -- should delete to zero when on grass (this works)",
gym/,126,"steer, gas, brake",
gym/,144,Create checkpoints,
gym/,158,"print ""\n"".join(str(h) for h in checkpoints)",
gym/,159,self.road_poly = [ (    # uncomment this to see checkpoints,
gym/,160,"[ (tx,ty) for a,tx,ty in checkpoints ],",
gym/,161,"(0.7,0.7,0.9) ) ]",
gym/,164,Go from one checkpoint to another to create track,
gym/,179,Find destination from checkpoints,
gym/,197,vector towards destination,
gym/,199,destination vector projected on rad,
gym/,218,"print ""\n"".join([str(t) for t in enumerate(track)])",
gym/,220,"Find closed loop range i1..i2, first loop should be ignored, second is OK",
gym/,226,Failed,
gym/,243,Length of perpendicular jump to put together head and tail,
gym/,250,Red-white border on hard turns,
gym/,266,Create tiles,
gym/,327,"First step without action, called from reset()",
gym/,329,"We actually don't want to count fuel spent, we want car to be faster.",
gym/,330,self.reward -=  10 * self.car.fuel_spent / ENGINE_POWER,
gym/,353,reset() not called yet,
gym/,355,Animate zoom first second,
gym/,388,pylint: disable=protected-access,
gym/,461,ABS sensors,
gym/,481,set 1.0 for wheels to block to zero rotation,
gym/,507,import matplotlib.pyplot as plt,
gym/,508,plt.imshow(s),
gym/,509,"plt.savefig(""test.jpeg"")",
gym/,11,Rocket trajectory optimization is a classic topic in Optimal Control.,
gym/,12,,
gym/,13,According to Pontryagin's maximum principle it's optimal to fire engine full throttle or,
gym/,14,turn it off. That's the reason this environment is OK to have discreet actions (engine on or off).,
gym/,15,,
gym/,16,"Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector.",
gym/,17,Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points.,
gym/,18,If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or,
gym/,19,"comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main",
gym/,20,engine is -0.3 points each frame. Firing side engine is -0.03 points each frame. Solved is 200 points.,
gym/,21,,
gym/,22,"Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land",
gym/,23,on its first attempt. Please see source code for details.,
gym/,24,,
gym/,25,"To see heuristic landing, run:",
gym/,26,,
gym/,27,python gym/envs/box2d/lunar_lander.py,
gym/,28,,
gym/,29,"To play yourself, run:",
gym/,30,,
gym/,31,python examples/agents/keyboard_agent.py LunarLander-v2,
gym/,32,,
gym/,33,Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.,
gym/,36,"affects how fast-paced the game is, forces should be adjusted as well",
gym/,41,Set 1500 to make game harder,
gym/,93,"useful range is -1 .. +1, but spikes can be higher",
gym/,97,"Action is two floats [main engine, left-right engines].",
gym/,98,"Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.",
gym/,99,"Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off",
gym/,102,"Nop, fire left engine, main engine, right engine",
gym/,132,terrain,
gym/,169,collide only with ground,
gym/,170,0.99 bouncy,
gym/,202,low enough not to jump back into the sky,
gym/,205,"Yes, the most esoteric numbers here, angles legs have freedom to travel within",
gym/,226,collide only with ground,
gym/,244,Engines,
gym/,251,Main engine,
gym/,253,0.5..1.0,
gym/,257,"4 is move a bit downwards, +-2 for randomness",
gym/,260,"particles are just a decoration, 3.5 is here to make particle speed adequate",
gym/,266,Orientation engines,
gym/,301,"And ten points for legs contact, the idea is if you",
gym/,302,"lose contact again after landing, you get negative reward",
gym/,307,"less fuel spent is better, about -30 for heurisic landing",
gym/,365,Heuristic for:,
gym/,366,1. Testing.,
gym/,367,2. Demonstration rollout.,
gym/,368,"angle should point towards center (s[0] is horizontal coordinate, s[2] hor speed)",
gym/,369,more than 0.4 radians (22 degrees) is bad,
gym/,371,target y should be proporional to horizontal offset,
gym/,373,"PID controller: s[4] angle, s[5] angularSpeed",
gym/,375,"print(""angle_targ=%0.2f, angle_todo=%0.2f"" % (angle_targ, angle_todo))",
gym/,377,PID controller: s[1] vertical coordinate s[3] vertical speed,
gym/,379,"print(""hover_targ=%0.2f, hover_todo=%0.2f"" % (hover_targ, hover_todo))",
gym/,381,legs have contact,
gym/,383,"override to reduce fall speed, that's all we need after contact",
gym/,12,This is simple 4-joints walker robot environment.,
gym/,13,,
gym/,14,There are two versions:,
gym/,15,,
gym/,16,"- Normal, with slightly uneven terrain.",
gym/,17,,
gym/,18,"- Hardcore with ladders, stumps, pitfalls.",
gym/,19,,
gym/,20,"Reward is given for moving forward, total 300+ points up to the far end. If the robot falls,",
gym/,21,"it gets -100. Applying motor torque costs a small amount of points, more optimal agent",
gym/,22,will get better score.,
gym/,23,,
gym/,24,"Heuristic is provided for testing, it's also useful to get demonstrations to",
gym/,25,learn from. To run heuristic:,
gym/,26,,
gym/,27,python gym/envs/box2d/bipedal_walker.py,
gym/,28,,
gym/,29,"State consists of hull angle speed, angular velocity, horizontal speed, vertical speed,",
gym/,30,"position of joints and joints angular speed, legs contact with ground, and 10 lidar",
gym/,31,rangefinder measurements to help to deal with the hardcore version. There's no coordinates,
gym/,32,"in the state vector. Lidar is less useful in normal version, but it works.",
gym/,33,,
gym/,34,To solve the game you need to get 300 points in 1600 time steps.,
gym/,35,,
gym/,36,To solve hardcore version you need 300 points in 2000 time steps.,
gym/,37,,
gym/,38,Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.,
gym/,41,"affects how fast-paced the game is, forces should be adjusted as well",
gym/,61,in steps,
gym/,63,"low long are grass spots, in steps",
gym/,64,in steps,
gym/,72,collide only with ground,
gym/,73,0.99 bouncy,
gym/,178,1,
gym/,277,"Sorry for the clouds, couldn't resist",
gym/,377,"self.hull.ApplyForceToCenter((0, 20), True) -- Uncomment this to receive a bit of stability help",
gym/,378,Should be easier as well,
gym/,408,"Normal angles up to 0.5 here, but sure more is possible.",
gym/,410,Normalized to get -1..1 range,
gym/,412,"This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)",
gym/,428,moving forward is a way to receive reward (normalized to get 300 on completion),
gym/,429,"keep head straight, other than that and falling, any behavior is unpunished",
gym/,438,"normalized to about -50.0 using heuristic, more optimal agent should spend less",
gym/,507,"Heurisic: suboptimal, have no notion of balance.",
gym/,514,Will fall forward on higher speed,
gym/,536,-0.8 .. +1.1,
gym/,537,-0.6 .. +0.9,
gym/,548,supporting leg is behind,
gym/,570,PID to keep head strait,
gym/,572,"vertical speed, to damp oscillations",
gym/,6,Top-down car dynamics simulation.,
gym/,7,,
gym/,8,Some ideas are taken from this great tutorial http://www.iforce2d.net/b2dtut/top-down-car by Chris Campbell.,
gym/,9,"This simulation is a bit more detailed, with wheels rotation.",
gym/,10,,
gym/,11,Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.,
gym/,16,friction ~= mass ~= size^2 (calculated implicitly using density),
gym/,86,wheel angle,
gym/,87,angular velocity,
gym/,114,"gradually increase, but stop immediately",
gym/,129,Steer each wheel,
gym/,134,Position => friction_limit,
gym/,136,Grass friction if no tile,
gym/,141,Force,
gym/,145,forward speed,
gym/,146,side speed,
gym/,148,WHEEL_MOMENT_OF_INERTIA*np.square(w.omega)/2 = E -- energy,
gym/,149,WHEEL_MOMENT_OF_INERTIA*w.omega * domega/dt = dE/dt = W -- power,
gym/,150,domega = dt*W/WHEEL_MOMENT_OF_INERTIA/w.omega,
gym/,151,small coef not to divide by zero,
gym/,157,radians per second,
gym/,160,low speed => same as = 0,
gym/,164,rotating wheel speed,
gym/,165,force direction is direction of speed difference,
gym/,168,Physically correct is to always apply friction_limit until speed is equal.,
gym/,169,"But dt is finite, that will lead to oscillations if difference is already near zero.",
gym/,170,Random coefficient to cut oscillations in few steps (have no effect on friction_limit),
gym/,174,Skid trace,
gym/,190,Correct physics here,
gym/,211,radians,
gym/,10,(JDS 2016/04/15): avoid bug on Anaconda 2.3.0 / Yosemite,
gym/,104,"In https://github.com/openai/gym-http-api/issues/2, we",
gym/,105,discovered that someone using Xmonad on Arch was having,
gym/,106,"a window of size 598 x 398, though a 600 x 400 window",
gym/,107,was requested. (Guess Xmonad was preserving a pixel for,
gym/,108,the boundary.) So we use the buffer height/width rather,
gym/,109,than the requested one.,
gym/,116,Convenience,
gym/,188,translate to GL loc ppint,
gym/,225,draw point,
gym/,238,draw each vertex,
gym/,287,draw each vertex,
gym/,317,================================================================,
gym/,358,draw,
gym/,362,"^^^ check sys.meta_path to avoid 'ImportError: sys.meta_path is None, Python is likely shutting down'",
gym/,1,-*- coding: utf-8 -*-,
gym/,38,"was 0.5 in gym, 0.45 in Arnaud de Broissia's version",
gym/,84,Convert a possible numpy bool to a Python bool.,
gym/,33,th := theta,
gym/,41,for rendering,
gym/,46,pylint: disable=E1111,
gym/,14,SOURCE:,
gym/,15,https://github.com/rlpy/rlpy/blob/master/rlpy/Domains/Acrobot.py,
gym/,65,[m],
gym/,66,[m],
gym/,67,: [kg] mass of link 1,
gym/,68,: [kg] mass of link 2,
gym/,69,: [m] position of the center of mass of link 1,
gym/,70,: [m] position of the center of mass of link 2,
gym/,71,: moments of inertia for both links,
gym/,80,: use dynamics equations from the nips paper or the book,
gym/,107,Add noise to the force action,
gym/,111,"Now, augment the state with our force action so it can be passed to",
gym/,112,_dsdt,
gym/,116,only care about final timestep of integration returned by integrator,
gym/,118,omit action,
gym/,119,ODEINT IS TOO SLOW!,
gym/,120,"ns_continuous = integrate.odeint(self._dsdt, self.s_continuous, [0, self.dt])",
gym/,121,self.s_continuous = ns_continuous[-1] # We only care about the state,
gym/,122,"at the ''final timestep'', self.dt",
gym/,164,the following line is consistent with the description in the,
gym/,165,paper,
gym/,169,the following line is consistent with the java implementation and the,
gym/,170,book,
gym/,183,2.2 for default,
gym/,241,bound x between min (m) and Max (M),
gym/,122,control with left and right arrow keys,
gym/,61,actually half the pole's length,
gym/,64,seconds between state updates,
gym/,67,Angle at which to fail the episode,
gym/,71,Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds,
gym/,106,semi-implicit euler,
gym/,121,Pole just fell!,
gym/,143,TOP OF CART,
gym/,178,Edit the pole polygon vertex,
gym/,184,MIDDLE OF CART,
gym/,45,Only 'promote' the length of generated input strings if the worst of the,
gym/,46,last n episodes was no more than this far from the maximum reward,
gym/,58,Keep track of this many past episodes,
gym/,60,Cumulative reward earned this episode,
gym/,62,Running tally of reward shortfalls. e.g. if there were 10 points to,
gym/,63,"earn and we got 8, we'd append -2",
gym/,70,TODO: Not clear why this is a class variable rather than instance.,
gym/,71,Could lead to some spooky action at a distance if someone is working,
gym/,72,with multiple algorithmic envs at once. Also makes testing tricky.,
gym/,74,Three sub-actions:,
gym/,75,1. Move read head left or right (or up/down),
gym/,76,2. Write or not,
gym/,77,3. Which character to write. (Ignored if should_write=0),
gym/,81,"Can see just what is on the input tape (one of n characters, or",
gym/,82,nothing),
gym/,183,Bail as soon as a wrong character is written to the tape,
gym/,202,(Seemingly arbitrary),
gym/,209,This is before the first episode/call to reset(). Nothing to do,
gym/,22,Quirk preserved for the sake of consistency: add the length of the input,
gym/,23,rather than the length of the desired output (which may differ if there's,
gym/,24,an extra carried digit).,
gym/,25,TODO: It seems like this time limit is so strict as to make Addition3-v0,
gym/,26,"unsolvable, since agents aren't even given enough time steps to look at",
gym/,27,all the digits. (The solutions on the scoreboard seem to only work by,
gym/,28,save-scumming.),
gym/,4,All concrete subclasses of AlgorithmicEnv,
gym/,52,Kind of a hack,
gym/,64,Should have leveled up on the last iteration,
gym/,70,Walk off the end,
gym/,75,Walk further off track,
gym/,79,Return to the first input character,
gym/,89,Corresponds to a grid that looks like...,
gym/,90,0 1 2,
gym/,91,3 4 5,
gym/,136,Test numerical alphabet rendering,
gym/,200,"DuplicatedInput needs to generate inputs with even length,",
gym/,201,so it may be short one,
gym/,209,"Should get ""size"" sublists, each of length self.rows (not the",
gym/,210,"opposite, as you might expect)",
gym/,223,"If requested input size isn't a multiple of duplication, go lower",
gym/,227,"If requested input size is *less than* duplication, go up",
gym/,52,Env methods,
gym/,53,----------------------------,
gym/,74,"Attempt to reset the simulator. Since we randomize initial conditions, it",
gym/,75,is possible to get into a state with numerical issues (e.g. due to penetration or,
gym/,76,Gimbel lock) or we may not achieve an initial condition (e.g. an object is within the hand).,
gym/,77,"In this case, we just keep randomizing until we eventually achieve a valid initial",
gym/,78,configuration.,
gym/,89,self.viewer.finish(),
gym/,97,window size used for old mujoco-py:,
gym/,99,"original image is upside-down, so flip it",
gym/,115,Extension methods,
gym/,116,----------------------------,
gym/,87,"obj1 is the mocap, obj2 is the welded body",
gym/,90,"obj2 is the mocap, obj1 is the welded body",
gym/,50,GoalEnv methods,
gym/,51,----------------------------,
gym/,54,Compute distance between goal and the achieved goal.,
gym/,61,RobotEnv methods,
gym/,62,----------------------------,
gym/,72,ensure that we don't change the action outside of this scope,
gym/,75,limit maximum change in position,
gym/,76,"fixed rotation of the end effector, expressed as a quaternion",
gym/,83,Apply action to simulation.,
gym/,88,positions,
gym/,95,rotations,
gym/,97,velocities,
gym/,100,gripper state,
gym/,106,change to a scalar if the gripper is made symmetric,
gym/,133,Visualize target.,
gym/,142,Randomize start position of object.,
gym/,176,Move end effector into position.,
gym/,184,Extract information for sampling goals.,
gym/,1,"Copyright (c) 2009-2017, Matthew Brett and Christoph Gohlke",
gym/,2,All rights reserved.,
gym/,3,,
gym/,4,"Redistribution and use in source and binary forms, with or without",
gym/,5,"modification, are permitted provided that the following conditions are",
gym/,6,met:,
gym/,7,,
gym/,8,"1. Redistributions of source code must retain the above copyright notice,",
gym/,9,this list of conditions and the following disclaimer.,
gym/,10,,
gym/,11,2. Redistributions in binary form must reproduce the above copyright,
gym/,12,"notice, this list of conditions and the following disclaimer in the",
gym/,13,documentation and/or other materials provided with the distribution.,
gym/,14,,
gym/,15,"THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS",
gym/,16,"IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,",
gym/,17,THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR,
gym/,18,PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR,
gym/,19,"CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,",
gym/,20,"EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
gym/,21,"PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR",
gym/,22,PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF,
gym/,23,"LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING",
gym/,24,NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS,
gym/,25,"SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
gym/,27,Many methods borrow heavily or entirely from transforms3d:,
gym/,28,https://github.com/matthew-brett/transforms3d,
gym/,29,They have mostly been modified to support batched operations.,
gym/,106,For testing whether a number is close to zero,
gym/,182,Fill only lower half of symmetric matrix,
gym/,195,TODO: vectorize this -- probably could be made faster,
gym/,199,"Use Hermitian eigenvectors, values for speed",
gym/,201,"Select largest eigenvector, reorder to w,x,y,z quaternion",
gym/,203,Prefer quaternion with positive w,
gym/,204,(q * -1 corresponds to same rotation as q),
gym/,320,"Should be in qw, qx, qy, qz",
gym/,19,RobotEnv methods,
gym/,20,----------------------------,
gym/,6,Ensure we get the path separator correct on windows,
gym/,6,Ensure we get the path separator correct on windows,
gym/,8,Ensure we get the path separator correct on windows,
gym/,6,Ensure we get the path separator correct on windows,
gym/,46,Ensure we get the path separator correct on windows,
gym/,72,GoalEnv methods,
gym/,73,----------------------------,
gym/,82,RobotEnv methods,
gym/,83,----------------------------,
gym/,112,Pick a meeting point above the hand.,
gym/,116,Slightly move meeting goal towards the respective finger to avoid that they,
gym/,117,overlap.,
gym/,125,"With some probability, ask all fingers to move back to the origin.",
gym/,126,This avoids that the thumb constantly stays near the goal position already.,
gym/,135,Visualize targets.,
gym/,143,Visualize finger positions.,
gym/,7,Ensure we get the path separator correct on windows,
gym/,50,get touch sensor site names and their ids,
gym/,55,set touch sensors rgba values,
gym/,80,this contains the object position + rotation,
gym/,81,"get touch sensor readings. if there is one, set value to 1",
gym/,22,Ensure we get the path separator correct on windows,
gym/,82,Object position and rotation.,
gym/,101,Special case: We want to ignore the Z component of the rotation.,
gym/,102,This code here assumes Euler angles with xyz convention. We first transform,
gym/,103,"to euler, then set the Z component to be equal between the two, and finally",
gym/,104,transform back into quaternions.,
gym/,110,Subtract quaternions and extract angle between them.,
gym/,117,GoalEnv methods,
gym/,118,----------------------------,
gym/,126,We weigh the difference in position to avoid that `d_pos` (in meters) is completely,
gym/,127,dominated by `d_rot` (in radians).,
gym/,130,RobotEnv methods,
gym/,131,----------------------------,
gym/,156,Randomization initial rotation.,
gym/,180,Randomize initial position.,
gym/,196,Run the simulation for a bunch of timesteps to let everything settle in.,
gym/,206,Select a goal for the object position.,
gym/,220,Select a goal for the object rotation.,
gym/,243,normalized quaternion,
gym/,248,Assign current state to target object but offset a bit so that the actual object,
gym/,249,is not obscured.,
gym/,253,Move the object to the side since we do not care about it's position.,
gym/,266,this contains the object position + rotation,
gym/,27,"This is really bad, str could be same while values change",
gym/,6,Test that FrozenLake map generation creates valid maps of various sizes.,
gym/,7,This runs a smoketest on each official registered env. We may want,
gym/,8,to try also running environments which are not officially registered,
gym/,9,envs.,
gym/,12,Capture warnings,
gym/,16,Check that dtype is explicitly declared for gym.Box spaces,
gym/,33,Make sure we can render the environment after close.,
gym/,39,Run a longer rollout on some environments,
gym/,7,https://github.com/openai/gym/issues/1266,
gym/,14,bet 20% of the wealth,
gym/,71,Raises KeyError because the new envs have extra info,
gym/,75,Raises KeyError because the new envs have extra info,
gym/,79,Raises KeyError because the new envs have extra info,
gym/,8,Note that this precludes running this test in multiple,
gym/,9,"threads. However, we probably already can't do multithreading",
gym/,10,due to some environments.,
gym/,38,Don't check rollout equality if it's a a nondeterministic,
gym/,39,environment.,
gym/,50,"Go returns a Pachi game board in info, which doesn't",
gym/,51,"properly check equality. For now, we hack around this by",
gym/,52,just skipping Go.,
gym/,18,We skip tests for envs that require dependencies or are otherwise,
gym/,19,troublesome to run frequently,
gym/,21,Skip mujoco tests for pull request CI,
gym/,1,-*- coding: utf-8 -*-,
gym/,54,must match an env name but not the version above,
gym/,40,Cliff Location,
gym/,44,Calculate transition probabilities and rewards,
gym/,54,Calculate initial state distribution,
gym/,55,"We always start in state (3, 0)",
gym/,97,Print terminal state,
gym/,26,+/- value the randomly select number can be between,
gym/,27,Action space bounds,
gym/,43,betting in penny,
gym/,44,increments,
gym/,46,"(w,b)",
gym/,64,action = desired bet in pennies,
gym/,114,store the hyper-parameters for passing back into __init__() during resets so,
gym/,115,"the same hyper-parameters govern the next game's parameters, as the user",
gym/,116,expects:,
gym/,117,"TODO: this is boilerplate, is there any more elegant way to do this?",
gym/,129,draw this game's set of parameters:,
gym/,135,add an additional global variable which is the sufficient statistic for the,
gym/,136,"Pareto distribution on wealth cap; alpha doesn't update, but x_m does, and",
gym/,137,simply is the highest wealth count we've seen to date:,
gym/,139,"for the coinflip edge, it is total wins/losses:",
gym/,142,"for the number of rounds, we need to remember how many rounds we've played:",
gym/,145,the rest proceeds as before:,
gym/,148,current wealth,
gym/,149,rounds elapsed,
gym/,150,wins,
gym/,151,losses,
gym/,152,maximum observed wealth,
gym/,189,"re-init everything to draw new parameters etc, but preserve the RNG for",
gym/,190,reproducibility and pass in the same hyper-parameters as originally specified:,
gym/,8,"1 = Ace, 2-10 = Number cards, Jack/Queen/King = 10",
gym/,20,Does this hand have a usable ace?,
gym/,24,Return current hand total,
gym/,30,Is this hand a bust?,
gym/,34,What is the score of this hand (0 if bust),
gym/,38,Is this hand a natural blackjack?,
gym/,81,"Flag to payout 1.5 on a ""natural"" blackjack win, like casino rules",
gym/,82,Ref: http://www.bicyclecards.com/how-to-play/blackjack/,
gym/,84,Start the first game,
gym/,93,hit: add a card to players hand and return,
gym/,101,"stick: play out the dealers hand, and score",
gym/,34,for rendering,
gym/,30,"observation, reward, done, info",
gym/,33,"N.B. np.random.randint draws from [A, B) while random.randint draws from [A,B]",
gym/,86,+1 for being inside taxi,
gym/,92,defaults,
gym/,94,default reward when there is no pickup/dropoff,
gym/,106,pickup,
gym/,109,passenger not at location,
gym/,111,dropoff,
gym/,118,dropoff at wrong location,
gym/,129,"(5) 5, 5, 4",
gym/,164,passenger in taxi,
gym/,175,No need to return anything for human,
gym/,41,Randomly selected number is within +/- this value,
gym/,42,DFS to check that it's a valid path.,
gym/,26,probability of 'slipping' an action,
gym/,27,payout for 'backwards' action,
gym/,28,payout at end of chain for 'forwards' action,
gym/,29,Start at beginning of the chain,
gym/,41,"agent slipped, reverse action taken",
gym/,42,"'backwards': go back to the beginning, get small reward",
gym/,45,'forwards': go up along the chain,
gym/,48,"'forwards': stay at the end of the chain, collect large reward",
gym/,85,methods to override:,
gym/,86,----------------------------,
gym/,103,-----------------------------,
gym/,146,window size used for old mujoco-py:,
gym/,148,"original image is upside-down, so flip it",
gym/,152,window size used for old mujoco-py:,
gym/,153,Extract depth part of the read_pixels() tuple,
gym/,155,"original image is upside-down, so flip it",
gym/,162,self.viewer.finish(),
gym/,2,^^^^^ so that user gets the correct error,
gym/,3,message if mujoco is not installed correctly,
gym/,25,cart x pos,
gym/,26,link angles,
gym/,43,v.model.stat.center[2],
gym/,61,Tune (or disable) ALE's action repeat:,
gym/,62,https://github.com/openai/gym/issues/349,
gym/,85,"Derive a random seed. This gets passed as a uint, but gets",
gym/,86,"checked as an int elsewhere, so we need to keep it below",
gym/,87,2**31.,
gym/,89,"Empirically, we need to seed before loading the ROM.",
gym/,142,"return: (states, observations)",
gym/tests/,88,make sure that unflatten(flatten(original)) == original,
gym/tests/,94,make sure that the values were flattened in the order they appeared in the,
gym/tests/,95,OrderedDict,
gym/tests/,82,Make sure we are testing the right environment for the test.,
gym/scripts/generate_json.py,28,Skip platform-dependent,
gym/scripts/generate_json.py,33,Skip environments that are nondeterministic,
gym/scripts/generate_json.py,43,"If running the env generates an exception, don't write to the rollout file",
gym/examples/agents/_policies.py,1,Support code for cem.py,
gym/examples/agents/keyboard_agent.py,1,!/usr/bin/env python,
gym/examples/agents/keyboard_agent.py,4,,
gym/examples/agents/keyboard_agent.py,5,"Test yourself as a learning agent! Pass environment name as a command-line argument, for example:",
gym/examples/agents/keyboard_agent.py,6,,
gym/examples/agents/keyboard_agent.py,7,python keyboard_agent.py SpaceInvadersNoFrameskip-v4,
gym/examples/agents/keyboard_agent.py,8,,
gym/examples/agents/keyboard_agent.py,15,"Use previous control decision SKIP_CONTROL times, that's how you",
gym/examples/agents/keyboard_agent.py,16,can test what skip is still usable.,
gym/examples/agents/keyboard_agent.py,50,"print(""taking action {}"".format(human_agent_action))",
gym/examples/agents/cem.py,7,Different file so it can be unpickled,
gym/examples/agents/cem.py,58,You provide the directory to write to (can be an existing,
gym/examples/agents/cem.py,59,"directory, but can't contain previous monitor results. You can",
gym/examples/agents/cem.py,60,also dump to a tempdir if you'd like: tempfile.mkdtemp().,
gym/examples/agents/cem.py,64,Prepare snapshotting,
gym/examples/agents/cem.py,65,----------------------------------------,
gym/examples/agents/cem.py,72,------------------------------------------,
gym/examples/agents/cem.py,79,"Train the agent, and snapshot each stage",
gym/examples/agents/cem.py,87,Write out the env at the end so we store the parameters of this,
gym/examples/agents/cem.py,88,environment.,
gym/examples/agents/random_agent.py,20,You can set the level to logger.DEBUG or logger.WARN if you,
gym/examples/agents/random_agent.py,21,want to change the amount of output.,
gym/examples/agents/random_agent.py,26,You provide the directory to write to (can be an existing,
gym/examples/agents/random_agent.py,27,"directory, including one with existing data -- all monitor files",
gym/examples/agents/random_agent.py,28,will be namespaced). You can also dump to a tempdir if you'd,
gym/examples/agents/random_agent.py,29,like: tempfile.mkdtemp().,
gym/examples/agents/random_agent.py,46,Note there's no env.render() here. But the environment still can open window and,
gym/examples/agents/random_agent.py,47,render if asked by env.monitor: it calls env.render('rgb_array') to record video.,
gym/examples/agents/random_agent.py,48,"Video is not recorded every episode, see capped_cubic_video_schedule for details.",
gym/examples/agents/random_agent.py,50,Close the env and write monitor result info to disk,
